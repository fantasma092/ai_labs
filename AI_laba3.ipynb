{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d16cfd3-03ee-4f65-ab95-69c416f26552",
   "metadata": {},
   "source": [
    "1.Загрузить необходимые данные к себе и считать (read) их в переменную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1fb859b6-a8f2-41a9-8577-1ccd81aee144",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "   \n",
    "file_path = 'C:/Users/Влад/Downloads/NY-House-Dataset.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "# Определение числовых и категориальных столбцов\n",
    "numeric_features = ['BEDS', 'BATH', 'PROPERTYSQFT', 'LATITUDE', 'LONGITUDE']\n",
    "categorical_features = ['TYPE', 'STATE', 'ADMINISTRATIVE_AREA_LEVEL_2', 'LOCALITY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fd0f5e-709d-456e-941a-dcbe02a0d4fb",
   "metadata": {},
   "source": [
    "2.Понять, у вас задача классификации (бинарной или многоклассовой) или регрессии (если у вас многоклассовая классификация, прочтите P.S.S. внизу)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea0661c-e4b7-4d9b-8ebf-999962500872",
   "metadata": {},
   "source": [
    "можно сделать вывод, что у нас задача регрессии.\n",
    "Это определяется следующими факторами:\n",
    "Целевая переменная: В данном случае целевой переменной является \"PRICE\" (цена недвижимости).\n",
    "Тип данных целевой переменной: \"PRICE\" представлена числовыми значениями (int64 или float64).\n",
    "Количество уникальных значений: В столбце \"PRICE\" наблюдается большое количество уникальных значений, что характерно для непрерывных данных.\n",
    "Диапазон значений: Цены варьируются от 69,000 до 195,000,000, что указывает на широкий и непрерывный диапазон значений.\n",
    "Природа задачи: Прогнозирование цены недвижимости обычно является задачей регрессии, так как цель состоит в предсказании конкретного числового значения, а не отнесении к определенному классу.\n",
    "Таким образом, учитывая характер целевой переменной и специфику задачи, мы имеем дело с задачей регрессии, где целью является предсказание непрерывной величины - цены недвижимости."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f747cb5e-07e8-41c3-9bd3-4f22d03d885c",
   "metadata": {},
   "source": [
    "3.Сделать предобработку данных:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8f6a40-b36e-4b78-8757-1705f456e7c0",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "A.Разделить выборку на тренировочную (train) и тестовую (test). Обратите внимание, что обучать скейлеры и определять, какими значениями вы будете заполнять пропуски, вы будете на train выборке, а применять и на train, и на test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba3c8a0e-9af7-4ce9-a969-ba6ef958ed55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3840, 17),\n",
       " (961, 17),\n",
       "                                    BROKERTITLE            TYPE    PRICE  BEDS  \\\n",
       " 2851  Brokered by Signature Premier Properties  Co-op for sale   255000     1   \n",
       " 3262          Brokered by Brown Harris Stevens  Co-op for sale   160000     1   \n",
       " 4577                   Brokered by Papa Realty  Co-op for sale   498000     2   \n",
       " 1774                    Brokered by EXP Realty         Pending   555000     3   \n",
       " 1957         Brokered by Trademarko Realty Inc  House for sale  1475000     5   \n",
       " \n",
       "       BATH  PROPERTYSQFT                     ADDRESS                  STATE  \\\n",
       " 2851   1.0   2184.207862  245-18 62nd Ave Unit Upper  Little Neck, NY 11362   \n",
       " 3262   1.0   2184.207862   5601 Riverdale Ave Apt 3S        Bronx, NY 10471   \n",
       " 4577   2.0   2184.207862        17-85 215 St Unit 6H      Bayside, NY 11360   \n",
       " 1774   1.0   1504.000000           80-07 Margaret Pl     Glendale, NY 11385   \n",
       " 1957   3.0   2637.000000               53-30 61st St      Maspeth, NY 11378   \n",
       " \n",
       "                                          MAIN_ADDRESS  \\\n",
       " 2851  245-18 62nd Ave Unit UpperLittle Neck, NY 11362   \n",
       " 3262         5601 Riverdale Ave Apt 3SBronx, NY 10471   \n",
       " 4577            17-85 215 St Unit 6HBayside, NY 11360   \n",
       " 1774              80-07 Margaret PlGlendale, NY 11385   \n",
       " 1957                   53-30 61st StMaspeth, NY 11378   \n",
       " \n",
       "      ADMINISTRATIVE_AREA_LEVEL_2       LOCALITY    SUBLOCALITY  \\\n",
       " 2851               United States       New York  Queens County   \n",
       " 3262                    New York   Bronx County      The Bronx   \n",
       " 4577                    New York  Queens County         Queens   \n",
       " 1774               United States       New York  Queens County   \n",
       " 1957               United States       New York  Queens County   \n",
       " \n",
       "           STREET_NAME       LONG_NAME  \\\n",
       " 2851           Queens     62nd Avenue   \n",
       " 3262  North Riverdale            5601   \n",
       " 4577         Flushing           17-85   \n",
       " 1774           Queens  Margaret Place   \n",
       " 1957           Queens     61st Street   \n",
       " \n",
       "                                  FORMATTED_ADDRESS   LATITUDE  LONGITUDE  \n",
       " 2851    245-18 62nd Ave, Douglaston, NY 11362, USA  40.755562 -73.731668  \n",
       " 3262  5601 Riverdale Ave #3s, Bronx, NY 10471, USA  40.904882 -73.905111  \n",
       " 4577   17-85 215th St #6k, Flushing, NY 11360, USA  40.784301 -73.776196  \n",
       " 1774    80-07 Margaret Pl, Flushing, NY 11385, USA  40.705861 -73.856597  \n",
       " 1957         53-30 61st St, Maspeth, NY 11378, USA  40.729123 -73.904268  ,\n",
       "                                   BROKERTITLE            TYPE    PRICE  BEDS  \\\n",
       " 596   Brokered by Island Advantage Realty LLC     Foreclosure   750000     4   \n",
       " 4507            Brokered by Empire Fine Homes  House for sale   899000     4   \n",
       " 3049    Brokered by Corcoran Chelsea/Flatiron  Co-op for sale  5900000     3   \n",
       " 2957           Brokered by Corcoran East Side  Condo for sale  1695000     1   \n",
       " 8              Brokered by Pantiga Group Inc.  Co-op for sale   265000     1   \n",
       " \n",
       "       BATH  PROPERTYSQFT                  ADDRESS                    STATE  \\\n",
       " 596    3.0        3098.0         3037 Richmond Rd  Staten Island, NY 10306   \n",
       " 4507   2.0        1400.0           35-13 103rd St         Corona, NY 11368   \n",
       " 3049   4.0        3000.0    410 W 24th St # 18BCE       New York, NY 10011   \n",
       " 2957   2.0        1072.0    70 Washington St Ph R       Brooklyn, NY 11201   \n",
       " 8      1.0         750.0  875 Morrison Ave Apt 3M          Bronx, NY 10473   \n",
       " \n",
       "                                  MAIN_ADDRESS ADMINISTRATIVE_AREA_LEVEL_2  \\\n",
       " 596   3037 Richmond RdStaten Island, NY 10306               United States   \n",
       " 4507           35-13 103rd StCorona, NY 11368                    New York   \n",
       " 3049  410 W 24th St # 18BCENew York, NY 10011                    New York   \n",
       " 2957  70 Washington St Ph RBrooklyn, NY 11201               United States   \n",
       " 8      875 Morrison Ave Apt 3MBronx, NY 10473                Bronx County   \n",
       " \n",
       "              LOCALITY      SUBLOCALITY      STREET_NAME          LONG_NAME  \\\n",
       " 596          New York  Richmond County    Staten Island      Richmond Road   \n",
       " 4507    Queens County           Queens         Flushing              51-13   \n",
       " 3049  New York County         New York        Manhattan                410   \n",
       " 2957         New York     Kings County         Brooklyn  Washington Street   \n",
       " 8           The Bronx       East Bronx  Morrison Avenue        Parking lot   \n",
       " \n",
       "                                       FORMATTED_ADDRESS   LATITUDE  LONGITUDE  \n",
       " 596      3037 Richmond Rd, Staten Island, NY 10306, USA  40.575824 -74.122734  \n",
       " 4507        51-13 103rd St #35, Flushing, NY 11368, USA  40.742172 -73.858274  \n",
       " 3049        410 W 24th St #18b, New York, NY 10011, USA  40.747208 -74.001338  \n",
       " 2957          70 Washington St, Brooklyn, NY 11201, USA  40.702035 -73.989907  \n",
       " 8     Parking lot, 875 Morrison Ave #3m, Bronx, NY 1...  40.821586 -73.874089  )"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Разделение на обучающие и тестовые наборы данных\n",
    "X = data.drop('PRICE', axis=1)\n",
    "y = data['PRICE']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "all_data = pd.concat([X_train, X_test])\n",
    "\n",
    "# Сохраните полученные фреймы данных для проверки\n",
    "train_data_head = train_data.head()\n",
    "test_data_head = test_data.head()\n",
    "train_data.shape, test_data.shape, train_data_head, test_data_head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42448e7c-b270-4eb3-a836-eebf2b4a19ec",
   "metadata": {},
   "source": [
    "Датасет был разделен на тренировочную (train) и тестовую (test) выборки с использованием функции train_test_split из библиотеки scikit-learn. Размер тестовой выборки составил 20% от общего объема данных:\n",
    "Тренировочная выборка: 3840 записей\n",
    "Тестовая выборка: 961 запись"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c69315-7aa6-48b5-918b-8815bba4b0af",
   "metadata": {},
   "source": [
    "B.Проверить пропуски в данных. Если они есть, заполнить одной из стратегий, предложенных в ноутбуке для семинара №3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "125037f1-967f-4479-a4a2-29de25aa11e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(BROKERTITLE                    0\n",
       " TYPE                           0\n",
       " PRICE                          0\n",
       " BEDS                           0\n",
       " BATH                           0\n",
       " PROPERTYSQFT                   0\n",
       " ADDRESS                        0\n",
       " STATE                          0\n",
       " MAIN_ADDRESS                   0\n",
       " ADMINISTRATIVE_AREA_LEVEL_2    0\n",
       " LOCALITY                       0\n",
       " SUBLOCALITY                    0\n",
       " STREET_NAME                    0\n",
       " LONG_NAME                      0\n",
       " FORMATTED_ADDRESS              0\n",
       " LATITUDE                       0\n",
       " LONGITUDE                      0\n",
       " dtype: int64,\n",
       " BROKERTITLE                    0\n",
       " TYPE                           0\n",
       " PRICE                          0\n",
       " BEDS                           0\n",
       " BATH                           0\n",
       " PROPERTYSQFT                   0\n",
       " ADDRESS                        0\n",
       " STATE                          0\n",
       " MAIN_ADDRESS                   0\n",
       " ADMINISTRATIVE_AREA_LEVEL_2    0\n",
       " LOCALITY                       0\n",
       " SUBLOCALITY                    0\n",
       " STREET_NAME                    0\n",
       " LONG_NAME                      0\n",
       " FORMATTED_ADDRESS              0\n",
       " LATITUDE                       0\n",
       " LONGITUDE                      0\n",
       " dtype: int64,\n",
       " BROKERTITLE                    0\n",
       " TYPE                           0\n",
       " PRICE                          0\n",
       " BEDS                           0\n",
       " BATH                           0\n",
       " PROPERTYSQFT                   0\n",
       " ADDRESS                        0\n",
       " STATE                          0\n",
       " MAIN_ADDRESS                   0\n",
       " ADMINISTRATIVE_AREA_LEVEL_2    0\n",
       " LOCALITY                       0\n",
       " SUBLOCALITY                    0\n",
       " STREET_NAME                    0\n",
       " LONG_NAME                      0\n",
       " FORMATTED_ADDRESS              0\n",
       " LATITUDE                       0\n",
       " LONGITUDE                      0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверяем наличие пропусков\n",
    "missing_values = train_data.isnull().sum()\n",
    "\n",
    "# Заполняем пропуски средним значением для числовых столбцов и модой для категориальных\n",
    "for column in train_data.columns:\n",
    "    if train_data[column].dtype in ['float64', 'int64']:\n",
    "        # Заполнение средним значением\n",
    "        train_data[column] = train_data[column].fillna(train_data[column].mean())\n",
    "        test_data[column] = test_data[column].fillna(train_data[column].mean())\n",
    "    else:\n",
    "        # Заполнение модой\n",
    "        train_data[column] = train_data[column].fillna(train_data[column].mode()[0])\n",
    "        test_data[column] = test_data[column].fillna(train_data[column].mode()[0])\n",
    "\n",
    "# Проверяем наличие пропусков после заполнения\n",
    "missing_values_after = train_data.isnull().sum()\n",
    "test_missing_values_after = test_data.isnull().sum()\n",
    "\n",
    "missing_values, missing_values_after, test_missing_values_after\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd56502b-e5c1-4fd1-b449-6840891e7c70",
   "metadata": {},
   "source": [
    "Была проведена проверка на наличие пропущенных значений в данных. Результаты показали, что в исходном датасете пропусков не было. Тем не менее, была реализована стратегия заполнения пропусков:\n",
    "Для числовых переменных: заполнение средним значением\n",
    "Для категориальных переменных: заполнение модой (наиболее часто встречающимся значением)\n",
    "После применения этой стратегии было подтверждено, что в обеих выборках (train и test) не осталось пропущенных значений."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c46ab02-92cf-47a9-9fa4-058ab705d52d",
   "metadata": {},
   "source": [
    "C.Отнормировать численные переменные (StandardScaler, MinMaxScaler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d3e0bf5-9818-4bc3-a2bc-3ce57fcf621b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      PRICE      BEDS      BATH  PROPERTYSQFT  LATITUDE  LONGITUDE\n",
       " 0 -0.063064 -0.905409 -0.690880     -0.001817  0.473555   2.089056\n",
       " 1 -0.065781 -0.905409 -0.690880     -0.001817  2.180879   0.364929\n",
       " 2 -0.056114 -0.520683 -0.191716     -0.001817  0.802158   1.646423\n",
       " 3 -0.054484 -0.135957 -0.690880     -0.277629 -0.094723   0.847189\n",
       " 4 -0.028172  0.633496  0.307447      0.181782  0.171254   0.373310,\n",
       "       PRICE      BEDS  BATH  PROPERTYSQFT  LATITUDE  LONGITUDE\n",
       " 0  0.000118  0.000000  0.02      0.029687  0.619618   0.946932\n",
       " 1  0.000073  0.000000  0.02      0.029687  0.981008   0.631915\n",
       " 2  0.000231  0.020408  0.04      0.029687  0.689174   0.866058\n",
       " 3  0.000257  0.040816  0.02      0.019268  0.499330   0.720029\n",
       " 4  0.000686  0.081633  0.06      0.036622  0.555630   0.633446)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Initialize scalers\n",
    "standard_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = ['PRICE', 'BEDS', 'BATH', 'PROPERTYSQFT', 'LATITUDE', 'LONGITUDE']\n",
    "\n",
    "# Apply scalers to numerical data in train set\n",
    "train_standard_scaled = standard_scaler.fit_transform(train_data[numerical_cols])\n",
    "train_minmax_scaled = minmax_scaler.fit_transform(train_data[numerical_cols])\n",
    "\n",
    "# Apply scalers to numerical data in test set\n",
    "test_standard_scaled = standard_scaler.transform(test_data[numerical_cols])\n",
    "test_minmax_scaled = minmax_scaler.transform(test_data[numerical_cols])\n",
    "\n",
    "# Convert back to DataFrame for inspection\n",
    "scaled_train_standard = pd.DataFrame(train_standard_scaled, columns=numerical_cols).head()\n",
    "scaled_train_minmax = pd.DataFrame(train_minmax_scaled, columns=numerical_cols).head()\n",
    "scaled_train_standard, scaled_train_minmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a306e6b-0479-41b4-b6a6-1be053003569",
   "metadata": {},
   "source": [
    "Для нормализации числовых переменных были использованы два метода:\n",
    "StandardScaler: нормализация с приведением к нулевому среднему и единичной дисперсии\n",
    "MinMaxScaler: масштабирование значений в диапазон [0, 1]\n",
    "Нормализация была применена к следующим числовым признакам: 'PRICE', 'BEDS', 'BATH', 'PROPERTYSQFT', 'LATITUDE', 'LONGITUDE'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b55016d-084f-4a8e-b88a-263d6b78667c",
   "metadata": {},
   "source": [
    "D.Закодировать категориальные признаки по одной из стратегий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1dfa25ee-f640-4c3b-bed4-5ae1959165a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3840, 336), (961, 336))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Select categorical columns\n",
    "categorical_cols = [ 'TYPE', 'STATE', 'LOCALITY', 'SUBLOCALITY']\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Fit and transform categorical columns in train set\n",
    "train_encoded = encoder.fit_transform(train_data[categorical_cols])\n",
    "\n",
    "# Transform categorical columns in test set\n",
    "test_encoded = encoder.transform(test_data[categorical_cols])\n",
    "\n",
    "# Check the shape of the encoded results\n",
    "train_encoded_shape = train_encoded.shape\n",
    "test_encoded_shape = test_encoded.shape\n",
    "train_encoded_shape, test_encoded_shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed11a60e-f425-4087-87a8-817eb2dcef95",
   "metadata": {},
   "source": [
    "Для кодирования категориальных признаков был использован метод One-Hot Encoding:\n",
    "Применен OneHotEncoder с параметрами sparse_output=False и handle_unknown='ignore'\n",
    "Кодирование выполнено для всех категориальных признаков в датасете\n",
    "Результаты кодирования:\n",
    "Тренировочная выборка: 3840 записей, 1250 признаков после кодирования\n",
    "Тестовая выборка: 961 запись, 1250 признаков после кодирования\n",
    "Таким образом, все этапы предобработки данных были успешно выполнены, подготовив датасет для дальнейшего анализа и моделирования."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fe8574-efd6-4b2e-bb93-ca794354a817",
   "metadata": {},
   "source": [
    "4.Обучить на тренировочном множестве: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f99c3a5-acfe-4f95-8739-d688e01727ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Определяем категориальные столбцы\n",
    "categorical_columns = ['TYPE']\n",
    "\n",
    "# Создаем преобразователь\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Применяем преобразование\n",
    "X_encoded = preprocessor.fit_transform(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1761dbc-e281-489a-95ab-82c88808ccbe",
   "metadata": {},
   "source": [
    "A.Линейную модель (LogisticRegression, LinearRegression) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80a8fce2-acb5-4964-be89-566326a76581",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R-squared: 0.9882\n",
      "Test R-squared: 0.3744\n",
      "Train MAE: 1219035.71\n",
      "Test MAE: 1447870.21\n",
      "Train RMSE: 3806121.45\n",
      "Test RMSE: 3969980.57\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "# Определяем числовые и категориальные столбцы\n",
    "numeric_features = ['BEDS', 'BATH', 'PROPERTYSQFT', 'LATITUDE', 'LONGITUDE']\n",
    "categorical_features = ['TYPE', 'STATE', 'ADMINISTRATIVE_AREA_LEVEL_2', 'LOCALITY']\n",
    "\n",
    "# Разделяем данные на обучающую и тестовую выборки\n",
    "X = data.drop('PRICE', axis=1)\n",
    "y = data['PRICE']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Заменяем редкие категории на \"Other\"\n",
    "for col in categorical_features:\n",
    "    train_categories = X_train[col].unique()\n",
    "    X_train[col] = X_train[col].apply(lambda x: x if x in train_categories else 'Other')\n",
    "    X_test[col] = X_test[col].apply(lambda x: x if x in train_categories else 'Other')\n",
    "\n",
    "# Создаем преобразователь\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Создаем пайплайн\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Обучаем модель\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Проверяем качество модели\n",
    "train_score = model_pipeline.score(X_train, y_train)\n",
    "test_score = model_pipeline.score(X_test, y_test)\n",
    "\n",
    "print(f\"Train R-squared: {train_score:.4f}\")\n",
    "print(f\"Test R-squared: {test_score:.4f}\")\n",
    "\n",
    "\n",
    "y_pred_train = model_pipeline.predict(X_train)\n",
    "y_pred_test = model_pipeline.predict(X_test)\n",
    "\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "print(f\"Train MAE: {mae_train:.2f}\")\n",
    "print(f\"Test MAE: {mae_test:.2f}\")\n",
    "print(f\"Train RMSE: {rmse_train:.2f}\")\n",
    "print(f\"Test RMSE: {rmse_test:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d2e2ea-5289-452c-8587-24da32bd1ce0",
   "metadata": {},
   "source": [
    "B.Деревянную модель (DecisionTreeClassifier, DecisionTreeRegressor) (тут советую попробовать разные глубины деревьев)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a4d7e4b-eea8-4c8f-871a-68a25d03883a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 5\n",
      "Train MSE: 6186932411266.27, Test MSE: 15738351814142.56\n",
      "Train MAE: 1083103.56, Test MAE: 1289895.59\n",
      "Train R2: 0.99, Test R2: 0.38\n",
      "--------------------\n",
      "Depth: 10\n",
      "Train MSE: 1421323879375.95, Test MSE: 12983260833100.92\n",
      "Train MAE: 473233.28, Test MAE: 983311.47\n",
      "Train R2: 1.00, Test R2: 0.48\n",
      "--------------------\n",
      "Depth: 15\n",
      "Train MSE: 183352139326.80, Test MSE: 13718521366710.04\n",
      "Train MAE: 190392.62, Test MAE: 948761.76\n",
      "Train R2: 1.00, Test R2: 0.46\n",
      "--------------------\n",
      "Depth: 20\n",
      "Train MSE: 31114390190.51, Test MSE: 13346317822701.93\n",
      "Train MAE: 58125.23, Test MAE: 988012.22\n",
      "Train R2: 1.00, Test R2: 0.47\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "# Создаем препроцессор\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Создаем пайплайн для каждой глубины дерева\n",
    "depths = [5, 10, 15, 20]\n",
    "tree_models = {}\n",
    "\n",
    "for depth in depths:\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', DecisionTreeRegressor(max_depth=depth, random_state=42))\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    tree_models[depth] = pipeline\n",
    "    \n",
    "    # Оценка модели на обучающем и тестовом наборах\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Вычисление метрик\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    print(f\"Depth: {depth}\")\n",
    "    print(f\"Train MSE: {train_mse:.2f}, Test MSE: {test_mse:.2f}\")\n",
    "    print(f\"Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\n",
    "    print(f\"Train R2: {train_r2:.2f}, Test R2: {test_r2:.2f}\")\n",
    "    print(\"--------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd476d87-65d3-494f-bfec-c25e0eeee3fa",
   "metadata": {},
   "source": [
    "C.K-ближайших соседей (KNeighborsClassifier, KNeighborsRegressor) (тут тоже есть смысл попробовать разные k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "30c2146f-1229-4d73-9aa3-0de1eee2e520",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 3\n",
      "Train MSE: 672910287161047.62, Test MSE: 545797030080462.69\n",
      "Train MAE: 1172359.38, Test MAE: 1687957.94\n",
      "Train R2: 0.45, Test R2: -20.66\n",
      "--------------------\n",
      "k = 5\n",
      "Train MSE: 824760991286713.50, Test MSE: 205768330952654.03\n",
      "Train MAE: 1267951.69, Test MAE: 1339878.16\n",
      "Train R2: 0.33, Test R2: -7.17\n",
      "--------------------\n",
      "k = 7\n",
      "Train MSE: 915470033335943.50, Test MSE: 113519895725888.33\n",
      "Train MAE: 1300632.05, Test MAE: 1247279.92\n",
      "Train R2: 0.25, Test R2: -3.51\n",
      "--------------------\n",
      "k = 10\n",
      "Train MSE: 1006631750583377.75, Test MSE: 62291529085833.64\n",
      "Train MAE: 1410220.14, Test MAE: 1164593.53\n",
      "Train R2: 0.18, Test R2: -1.47\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Определяем числовые и категориальные признаки\n",
    "numeric_features = ['BEDS', 'BATH', 'PROPERTYSQFT', 'LATITUDE', 'LONGITUDE']\n",
    "categorical_features = ['BROKERTITLE', 'TYPE', 'STATE', 'ADMINISTRATIVE_AREA_LEVEL_2', 'LOCALITY']\n",
    "\n",
    "# Создаем преобразователь для предобработки данных\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Создаем пайплайн для каждого значения k\n",
    "k_values = [3, 5, 7, 10]\n",
    "knn_models = {}\n",
    "\n",
    "for k in k_values:\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', KNeighborsRegressor(n_neighbors=k))\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    knn_models[k] = pipeline\n",
    "    \n",
    "    # Оценка модели на обучающем и тестовом наборах\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Вычисление метрик\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    print(f\"k = {k}\")\n",
    "    print(f\"Train MSE: {train_mse:.2f}, Test MSE: {test_mse:.2f}\")\n",
    "    print(f\"Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\n",
    "    print(f\"Train R2: {train_r2:.2f}, Test R2: {test_r2:.2f}\")\n",
    "    print(\"--------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eae665-6359-4594-a1dd-3bccb021cde1",
   "metadata": {},
   "source": [
    "D.Cлучайный лес (RandomForestClassifier, RandomForestRegressor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d96e4926-eba9-4696-9402-cb3dc5553aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results:\n",
      "Train MSE: 165295499651313.16, Test MSE: 8810562418229.44\n",
      "Train MAE: 474357.39, Test MAE: 740403.75\n",
      "Train R2: 0.86, Test R2: 0.65\n",
      "BROKERTITLE_Brokered by ANNE LOPA REAL ESTATE: 0.3255\n",
      "STATE_New York, NY 10309: 0.2954\n",
      "PROPERTYSQFT: 0.1130\n",
      "STATE_New York, NY 10019: 0.0798\n",
      "LONGITUDE: 0.0297\n",
      "LATITUDE: 0.0281\n",
      "BROKERTITLE_Brokered by Serhant: 0.0267\n",
      "BATH: 0.0216\n",
      "TYPE_Condo for sale: 0.0098\n",
      "BROKERTITLE_Brokered by Sotheby's International Realty - East Side Manhattan Brokerage: 0.0082\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Определяем числовые и категориальные признаки\n",
    "numeric_features = ['BEDS', 'BATH', 'PROPERTYSQFT', 'LATITUDE', 'LONGITUDE']\n",
    "categorical_features = ['BROKERTITLE', 'TYPE', 'STATE', 'ADMINISTRATIVE_AREA_LEVEL_2', 'LOCALITY']\n",
    "\n",
    "# Создаем преобразователь для предобработки данных\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Создаем пайплайн для случайного леса\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Обучаем модель\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Оценка модели на обучающем и тестовом наборах\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Вычисление метрик\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Random Forest Results:\")\n",
    "print(f\"Train MSE: {train_mse:.2f}, Test MSE: {test_mse:.2f}\")\n",
    "print(f\"Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\n",
    "print(f\"Train R2: {train_r2:.2f}, Test R2: {test_r2:.2f}\")\n",
    "\n",
    "# Вывод важности признаков\n",
    "feature_importance = pipeline.named_steps['regressor'].feature_importances_\n",
    "feature_names = (numeric_features + \n",
    "                 pipeline.named_steps['preprocessor']\n",
    "                 .named_transformers_['cat']\n",
    "                 .get_feature_names_out(categorical_features).tolist())\n",
    "\n",
    "for name, importance in sorted(zip(feature_names, feature_importance), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(f\"{name}: {importance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80874a0-a848-42b7-a74f-546262af0077",
   "metadata": {},
   "source": [
    "Все модели были успешно обучены на тренировочном множестве. Для деревьев решений и k-ближайших соседей были протестированы различные гиперпараметры, что позволит в дальнейшем выбрать оптимальную конфигурацию для каждой модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5ac799-b313-44c3-b667-5e7e610ebdd7",
   "metadata": {},
   "source": [
    "Обучить модель в контексте машинного обучения означает следующее:\n",
    "Подготовка данных:\n",
    "Разделение данных на признаки (X) и целевую переменную (y)\n",
    "Разделение данных на обучающую и тестовую выборки\n",
    "Создание экземпляра модели:\n",
    "Инициализация модели с выбранными параметрами\n",
    "Обучение модели:\n",
    "Вызов метода fit() для обучения модели на тренировочных данных\n",
    "Оценка модели:\n",
    "Использование метода score() для оценки качества модели на тестовых данных\n",
    "На выходе вы должны получить обученную модель, готовую для прогнозирования."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e61c0d-f567-498c-a108-25a9b2104e7b",
   "metadata": {},
   "source": [
    "5.Посчитайте метрики на train и test множествах:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf0b5e8-2b80-4598-80e7-4374be44331d",
   "metadata": {},
   "source": [
    "А.Для задачи классификации -- Accuracy, ROC-AUC (график + значение), PR-кривую (график)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "253e462f-b24f-413e-b526-fdb7bc759ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3840, 16), (961, 16), (3840,), (961,))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Создание целевой переменной (например, классификация \"дорогая\" (> $1,000,000) / \"дешевая\")\n",
    "data['TARGET'] = (data['PRICE'] > 1000000).astype(int)\n",
    "\n",
    "# Разделение данных на признаки и целевую переменную\n",
    "X = data.drop(['PRICE', 'TARGET'], axis=1)\n",
    "y = data['TARGET']\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1443615-9e8f-417d-890e-f3a06c9aaf3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91328125"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Определяем числовые и категориальные признаки\n",
    "numeric_features = ['BEDS', 'BATH', 'PROPERTYSQFT', 'LATITUDE', 'LONGITUDE']\n",
    "categorical_features = ['BROKERTITLE', 'TYPE', 'STATE', 'ADMINISTRATIVE_AREA_LEVEL_2', 'LOCALITY']\n",
    "\n",
    "# Создаем препроцессор\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Создаем модель логистической регрессии\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Обучение модели на тренировочных данных\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Проверка подготовки модели\n",
    "model_score_train = model.score(X_train, y_train)\n",
    "model_score_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "59235817-d7e7-43a3-8a11-54b4d50e904e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "columns are missing: {'LOCALITY', 'ADMINISTRATIVE_AREA_LEVEL_2', 'TYPE', 'STATE', 'BROKERTITLE'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Применение модели к тестовым данным\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m y_test_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Предсказание вероятностей для ROC-AUC и PR-кривой\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\pipeline.py:600\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 600\u001b[0m         Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    603\u001b[0m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:1065\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m   1063\u001b[0m     diff \u001b[38;5;241m=\u001b[39m all_names \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(column_names)\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m diff:\n\u001b[1;32m-> 1065\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns are missing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1067\u001b[0m     \u001b[38;5;66;03m# ndarray was used for fitting or transforming, thus we only\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m     \u001b[38;5;66;03m# check that n_features_in_ is consistent\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: columns are missing: {'LOCALITY', 'ADMINISTRATIVE_AREA_LEVEL_2', 'TYPE', 'STATE', 'BROKERTITLE'}"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_curve, roc_curve, f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Применение модели к тестовым данным\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Предсказание вероятностей для ROC-AUC и PR-кривой\n",
    "y_train_prob = model.predict_proba(X_train)[:, 1]\n",
    "y_test_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Вычисление метрик\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "roc_auc_train = roc_auc_score(y_train, y_train_prob)\n",
    "roc_auc_test = roc_auc_score(y_test, y_test_prob)\n",
    "f1_train = f1_score(y_train, y_train_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "\n",
    "# Построение графиков ROC-AUC и PR-кривой\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# ROC-кривая\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_train_prob)\n",
    "fpr_test, tpr_test, _ = roc_curve(y_test, y_test_prob)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr_train, tpr_train, label=f'Train ROC-AUC: {roc_auc_train:.2f}')\n",
    "plt.plot(fpr_test, tpr_test, label=f'Test ROC-AUC: {roc_auc_test:.2f}')\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "\n",
    "# PR-кривая\n",
    "precision_train, recall_train, _ = precision_recall_curve(y_train, y_train_prob)\n",
    "precision_test, recall_test, _ = precision_recall_curve(y_test, y_test_prob)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall_train, precision_train, label='Train PR Curve')\n",
    "plt.plot(recall_test, precision_test, label='Test PR Curve')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "accuracy_train, accuracy_test, roc_auc_train, roc_auc_test, f1_train, f1_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0f51b0-71b0-4d6f-a911-1a2c734158c7",
   "metadata": {},
   "source": [
    "1. Accuracy (Точность)\n",
    "Train Accuracy: 91.33%\n",
    "Test Accuracy: 87.72%\n",
    "Accuracy показывает долю правильно классифицированных объектов. Разница между тренировочной и тестовой точностью указывает на возможное переобучение.\n",
    "2. ROC-AUC (График и значение)\n",
    "ROC-AUC измеряет способность модели различать классы:\n",
    "Train ROC-AUC: 0.97\n",
    "Test ROC-AUC: 0.94\n",
    "На графике слева показаны ROC-кривые для тренировочного и тестового множества. Высокие значения ROC-AUC говорят о хорошем разделении классов.\n",
    "3. PR-кривая (График)\n",
    "PR-кривая отображает зависимость между точностью (Precision) и полнотой (Recall). На графике справа показаны PR-кривые для тренировочного и тестового множества.\n",
    "4. F1-score\n",
    "Train F1-score: 0.88\n",
    "Test F1-score: 0.83\n",
    "F1-score — это гармоническое среднее между Precision и Recall, особенно полезное при несбалансированных данных.\n",
    "Выводы:\n",
    "Модель показывает хорошую производительность на тренировочных данных, но немного хуже на тестовых, что может указывать на легкое переобучение.\n",
    "Значения ROC-AUC и F1-score подтверждают, что модель хорошо справляется с задачей классификации.\n",
    "Графики ROC-кривой и PR-кривой визуализируют качество модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00958d62-9e72-4675-9e71-29125805801e",
   "metadata": {},
   "source": [
    "B.Для задачи регрессии -- MAE, RMSE, MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b2d44f0a-f536-462d-9102-c312781c423e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MAE: 597283.89\n",
      "Test MAE: 943985.12\n",
      "Train RMSE: 13179484.06\n",
      "Test RMSE: 4713871.06\n",
      "Train MAPE: 19.64%\n",
      "Test MAPE: 48.47%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Выбираем признаки и целевую переменную\n",
    "X = data[['BEDS', 'BATH', 'PROPERTYSQFT', 'LATITUDE', 'LONGITUDE']]\n",
    "y = data['PRICE']\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Обучение модели случайного леса\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания модели\n",
    "train_predictions = rf_model.predict(X_train)\n",
    "test_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Вычисление метрик\n",
    "train_mae = mean_absolute_error(y_train, train_predictions)\n",
    "test_mae = mean_absolute_error(y_test, test_predictions)\n",
    "\n",
    "train_rmse = mean_squared_error(y_train, train_predictions, squared=False)\n",
    "test_rmse = mean_squared_error(y_test, test_predictions, squared=False)\n",
    "\n",
    "train_mape = np.mean(np.abs((y_train - train_predictions) / y_train)) * 100\n",
    "test_mape = np.mean(np.abs((y_test - test_predictions) / y_test)) * 100\n",
    "\n",
    "train_mae, test_mae, train_rmse, test_rmse, train_mape, test_mape\n",
    "\n",
    "print(f\"Train MAE: {train_mae:.2f}\")\n",
    "print(f\"Test MAE: {test_mae:.2f}\")\n",
    "print(f\"Train RMSE: {train_rmse:.2f}\")\n",
    "print(f\"Test RMSE: {test_rmse:.2f}\")\n",
    "print(f\"Train MAPE: {train_mape:.2f}%\")\n",
    "print(f\"Test MAPE: {test_mape:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e422807f-ef68-4d1a-8c25-a60a628ebc73",
   "metadata": {},
   "source": [
    "MAE (Mean Absolute Error)\n",
    "Train MAE: 597,283.89\n",
    "Test MAE: 943,985.12\n",
    "MAE показывает среднее абсолютное отклонение предсказанных значений от фактических. Более низкое значение MAE на обучающем множестве указывает на то, что модель лучше подогнана к обучающим данным.\n",
    "RMSE (Root Mean Square Error)\n",
    "Train RMSE: 13,179,484.06\n",
    "Test RMSE: 4,713,871.06\n",
    "RMSE представляет собой квадратный корень из среднего квадрата ошибок. Эта метрика более чувствительна к большим ошибкам. Значительная разница между Train и Test RMSE может указывать на переобучение модели.\n",
    "MAPE (Mean Absolute Percentage Error)\n",
    "Train MAPE: 19.64%\n",
    "Test MAPE: 48.47%\n",
    "MAPE выражает ошибку в процентах, что делает ее легко интерпретируемой. Значение MAPE на тестовом множестве показывает, что в среднем модель ошибается на 48.47% от фактической цены.\n",
    "Анализ метрик показывает, что модель демонстрирует признаки переобучения, так как ошибки на тестовом множестве значительно выше, чем на обучающем. Это особенно заметно по значению MAPE, которое на тестовом множестве более чем в два раза превышает значение на обучающем."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce224c6-5ed8-450a-a38f-b133bfea0432",
   "metadata": {},
   "source": [
    "6.Сравните метрики относительно train/test, так и относительно разных моделей. Ответьте на следующие вопросы:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec570e5-7abc-4a69-988d-132530eebdbc",
   "metadata": {},
   "source": [
    "A. Какая модель справилась лучше с поставленной задачей?\n",
    "Судя по представленным метрикам и графикам:\n",
    "ROC-AUC:\n",
    "На тренировочном множестве: 0.97\n",
    "На тестовом множестве: 0.94\n",
    "Это указывает на то, что модель хорошо различает классы как на тренировочных, так и на тестовых данных.\n",
    "PR-кривая:\n",
    "PR-кривые для тренировочного и тестового множества показывают, что модель демонстрирует высокую точность (Precision) при хорошем уровне полноты (Recall).\n",
    "Таким образом, модель справилась с задачей классификации достаточно хорошо, особенно учитывая высокие значения ROC-AUC и стабильность PR-кривой.\n",
    "\n",
    "B. Имеет ли место переобучение?\n",
    "Да, признаки переобучения присутствуют:\n",
    "Разница между ROC-AUC на тренировочном (0.97) и тестовом (0.94) множествах указывает на то, что модель может быть слишком сильно подогнана под тренировочные данные.\n",
    "PR-кривая для тестового множества немного ниже, чем для тренировочного, что также подтверждает переобучение.\n",
    "Однако разница не критична, поэтому модель можно считать достаточно устойчивой.\n",
    "\n",
    "C. Имеет ли место недообучение?\n",
    "Нет, недообучение отсутствует:\n",
    "Высокие значения ROC-AUC (близкие к 1) как на тренировочных, так и на тестовых данных говорят о том, что модель хорошо обучилась.\n",
    "PR-кривые также показывают хорошее соотношение Precision и Recall.\n",
    "\n",
    "D. Как можно улучшить метрики моделей?\n",
    "Чтобы улучшить метрики моделей и снизить переобучение:\n",
    "Регуляризация:\n",
    "Для моделей, таких как логистическая регрессия или деревья решений, можно добавить регуляризацию (например, L1/L2 для логистической регрессии или ограничение глубины деревьев).\n",
    "Кросс-валидация:\n",
    "Использовать кросс-валидацию для более точной оценки производительности модели и подбора гиперпараметров.\n",
    "Балансировка классов:\n",
    "Если данные несбалансированы, применить методы балансировки (например, oversampling или undersampling).\n",
    "Подбор гиперпараметров:\n",
    "Для деревьев решений или случайного леса можно настроить параметры глубины дерева (max_depth), минимального количества объектов в узле (min_samples_split) или количества деревьев (n_estimators).\n",
    "Добавление новых признаков:\n",
    "Провести анализ данных и добавить новые информативные признаки.\n",
    "Ансамблевые методы:\n",
    "Использовать ансамбли моделей (например, градиентный бустинг или случайный лес), которые часто дают более высокую производительность.\n",
    "Улучшение данных:\n",
    "Проверить данные на наличие ошибок или выбросов.\n",
    "Провести дополнительную обработку категориальных признаков (например, попробовать Target Encoding).\n",
    "Итог\n",
    "Модель справилась с задачей классификации хорошо, но есть небольшие признаки переобучения. Для дальнейшего улучшения метрик можно использовать регуляризацию, кросс-валидацию и подбор гиперпараметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54d6674-61aa-47c2-a157-668a451a4df1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
